{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "\n",
    "# prepare table + question\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "question = \"abc\"\n",
    "\n",
    "encoding = tokenizer(table, question, return_tensors=\"pt\")\n",
    "\n",
    "# let the model generate an answer autoregressively\n",
    "outputs = model.generate(**encoding)\n",
    "\n",
    "# decode back to text\n",
    "predicted_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-tabfact\")\n",
    "col_tokens = tokenizer.tokenize(\"Brad Pitt\")\n",
    "input_ids = tokenizer.convert_tokens_to_ids(col_tokens)\n",
    "print(col_tokens)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\"], \"Number of movies\": [\"87\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Actors\": [\"\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"\": [\"\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_output_before_lm_head(model, tokenizer, table, question):\n",
    "    # Tokenize the table and question\n",
    "    encoding = tokenizer(table, question, return_tensors=\"pt\")\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding.get('attention_mask', None)\n",
    "\n",
    "    # Directly use the model's BART structure to get the encoder's output\n",
    "    encoder_outputs = model.model.encoder(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Retrieve decoder's output using encoder's outputs and attention mask\n",
    "    decoder_outputs = model.model.decoder(\n",
    "        input_ids=input_ids, \n",
    "        encoder_hidden_states=encoder_outputs[0], \n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    # The first output of the decoder contains the last hidden states\n",
    "    return decoder_outputs[0]\n",
    "\n",
    "# Example usage:\n",
    "decoder_output = get_decoder_output_before_lm_head(model, tokenizer, table, question)\n",
    "print(decoder_output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
