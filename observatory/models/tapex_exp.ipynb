{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ben\\anaconda3\\envs\\545\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 1024 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kalimba edwards\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/tapex-large-finetuned-wtq\")\n",
    "\n",
    "# prepare table + question\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "question = \"abc\"\n",
    "\n",
    "encoding = tokenizer(table, question, return_tensors=\"pt\")\n",
    "\n",
    "# let the model generate an answer autoregressively\n",
    "outputs = model.generate(**encoding)\n",
    "\n",
    "# decode back to text\n",
    "predicted_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'ors']\n",
      "[7257, 994]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/tapex-large-finetuned-tabfact\")\n",
    "col_tokens = tokenizer.tokenize(\"Actors\")\n",
    "input_ids = tokenizer.convert_tokens_to_ids(col_tokens)\n",
    "print(col_tokens)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  9119,  4832,  5552,  1721,   346,     9,  4133,  3236,   112,\n",
      "          4832,  5378,   625,   181,  2582,  1721,  8176,  3236,   132,  4832,\n",
      "          2084,   261,  6782,  2269,  2927, 12834,  1721,  4268,  3236,   155,\n",
      "          4832,  5473, 26875, 42771,  6071,  1721,  5913,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0, 9119, 4832, 5552, 1721,  346,    9, 4133, 3236,  112, 4832, 5378,\n",
      "          625,  181, 2582, 1721, 8176,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\"], \"Number of movies\": [\"87\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  9119,  4832,  5552,  3236,   112,  4832,  5378,   625,   181,\n",
      "          2582,  3236,   132,  4832,  2084,   261,  6782,  2269,  2927, 12834,\n",
      "          3236,   155,  4832,  5473, 26875, 42771,  6071,     2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  9119,  4832,  5552,  3236,   112,  4832,  5378,   625,   181,\n",
      "          2582,  3236,   132,  4832,  2084,   261,  6782,  2269,  2927, 12834,\n",
      "             2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 9119, 4832, 5552, 3236,  112, 4832, 5378,  625,  181, 2582,    2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"Brad Pitt\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide an empty table, or all cells contain much tokens (e.g., >= 1024 tokens). Please carefully check the corresponding table with the query : .\n",
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [], \"Number of movies\": []}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 9119, 4832, 5552, 3236,  112, 4832,    2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"Actors\": [\"\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 9119, 4832, 1437, 3236,  112, 4832,    2]])\n"
     ]
    }
   ],
   "source": [
    "data = {\"\": [\"\"]}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provide nothing to query with respect to the table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 38])\n",
      "torch.Size([1, 38])\n",
      "torch.Size([2, 38])\n",
      "torch.Size([2, 38])\n",
      "torch.Size([2, 38, 1024])\n",
      "torch.Size([2, 38, 1024])\n"
     ]
    }
   ],
   "source": [
    "def get_decoder_output_before_lm_head(model, tokenizer, table):\n",
    "    # Tokenize the table and question\n",
    "    encoding = tokenizer(table, \"\", return_tensors=\"pt\")\n",
    "    input_ids = encoding['input_ids']\n",
    "    print(input_ids.shape)\n",
    "    \n",
    "    attention_mask = encoding.get('attention_mask', None)\n",
    "    print(attention_mask.shape)\n",
    "    batch_input_ids = torch.cat([input_ids,input_ids], dim=0)\n",
    "    batch_attention_mask = torch.cat([attention_mask,attention_mask], dim=0)\n",
    "    print(batch_input_ids.shape)\n",
    "    print(batch_attention_mask.shape)\n",
    "    \n",
    "    # Directly use the model's BART structure to get the encoder's output\n",
    "    encoder_outputs = model.model.encoder(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "    print(encoder_outputs[0].shape)\n",
    "\n",
    "    # Retrieve decoder's output using encoder's outputs and attention mask\n",
    "    decoder_outputs = model.model.decoder(\n",
    "        input_ids=batch_input_ids, \n",
    "        encoder_hidden_states=encoder_outputs[0], \n",
    "        attention_mask=batch_attention_mask\n",
    "    )\n",
    "\n",
    "    # The first output of the decoder contains the last hidden states\n",
    "    return decoder_outputs[0]\n",
    "\n",
    "# Example usage:\n",
    "decoder_output = get_decoder_output_before_lm_head(model, tokenizer, table)\n",
    "print(decoder_output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "545",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
